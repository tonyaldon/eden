Eden is an AI assistant package for Emacs.

It offers a simple interface for:

1) OpenAI LLM models such as ~gpt-4o~ and ~o1~ as well as
2) Perplexity AI powered answer engine.

It also supports any OpenAI-compatible API.

* Get started in minutes

1) Ensure the following utilities are installed and present in one
   of your ~exec-path~ directories:

   - ~curl~
   - ~uuidgen~
   - ~pandoc~

2) Add the directory containing ~eden.el~ to your ~load-path~ and
   require the Eden package by adding the following lines to your init
   file, ensuring to replace ~/path/to/eden/~ with the appropriate
   directory:

   #+BEGIN_SRC emacs-lisp
   (add-to-list 'load-path "/path/to/eden/")
   (require 'eden)
   #+END_SRC

3) Store your OpenAI API key in either the ~~/.authinfo.gpg~ file
   (encrypted with ~gpg~) or the ~~/.authinfo~ file (plaintext):

   - After funding your [[https://platform.openai.com][OpenAI account]] ($5.00 is enough to get
     started), create an OpenAI API key visiting
     https://platform.openai.com/api-keys.
   - Add the API key in the selected file as follows:

     #+BEGIN_SRC authinfo
     machine openai password <openai-api-key>
     #+END_SRC

     where ~<openai-api-key>~ is your API key.

4) Call the command ~eden~ to switch to ~*eden*~ prompt buffer,
5) Enter your prompt,
6) Press ~C-c C-c~ to send your prompt to OpenAI API,
7) Finally, the response will asynchronously show up in a dedicated
   buffer upon receipt.

* Utility requirements

Ensure the following utilities are installed and available in one of
~exec-path~ directories:

- ~curl~
- ~uuidgen~
- ~pandoc~

* Eden is simple

Eden is simple and rely exclusively on the ~eden~ command:

1) This command lets you switch to the prompt buffer displayed at the
   bottom of the frame on demand.  Once in that buffer (in ~eden-mode~)
   you can enter your prompt using ~org-mode~ syntax and send it to
   ~eden-api~ with ~eden-send~ command bound by default to ~C-c C-c~.

2) It also lets you manage conversations and settings via a transient
   command, if it is called from the prompt buffer.  Specifically,
   calling it that way invokes ~eden-menu~, and after the menu poped up,
   you can for instance:

   - Start a new conversation pressing the key ~n~,
   - Switch to an existing conversation pressing the ~TAB~ key,
   - Paused a conversation pressing the ~SPC~ key,
   - Show the current settings pressing the key ~S~,
   - Set the current API pressing the key ~a~ or
   - Set the system message pressing the key ~'~.

3) Finally it can be used to continue a conversation from a request at
   point, or only inspect it, if we call it with the prefix argument
   ~C-u~.  Indeed, doing so invokes ~eden-req-at-point-menu~ which provides
   a menu with accepted actions on the request at point.

* Eden keeps all your requests in eden-dir

An important aspect of Eden is that none of the questions you asked to
the underlying LLM is lost.

Eden keeps every request sent to the OpenAI-compatible API in the
directory ~eden-dir~.  By default, it is the subdirectory ~eden~ in your
~user-emacs-directory~.

Each request is identified by a UUID used as subdirectory in ~eden-dir~,
where relevant information about request are stored.

There some benefits to do that among these are:

- you can forget about your request, it will always be there,
- if you copied the org heading with the request's UUID somewhere else
  in your notes, you can lookup the request, jump to the directory and
  get all the information associated the request, API, model, system
  prompt, timestamp...
- if an error occurs while proceding the request, you can consult the
  ~error.json~ of that request and troubleshoot it,
- You can start or continue a conversation from any existing request
  (it seems to be called ~branching~):
  - either from req at point ... from a conversation in your notes
  - or in prompt buffer, navigate the history with M-p, M-n to find
    the request you're interested in, call ~eden~ to pop up the menu and
    press ~c~ to continue the conversation where you left it
- everything in json (or text format), so you can feed it to other
  software of your choice to analyze you request for instance,...

* Eden focuses on conversations but doesn't impose it

By default every requests sent are independant.

If you want to have a conversation where previous exchanges are
including belonging to that conversation are sent with newer request,
you have to start or continue a conversation.

There several way to do that while you are in the prompt buffer:

1) You can start a conversation by calling ~eden~ command, pressing ~n~
   and entering its title.  This made that new empty conversation the
   current one, and each new request will be part of it.
2) You can start a conversation from the current request in history
   excluding previous exchanges.  First, use M-p and M-n to navigate
   the prompt history to find the request from which the conversation
   will start.  Then, call ~eden~ command, press ~s~ and enter its title.
   This made that new conversation, with already one exchange, the
   current one, and each new request will be part of it.
3) You can also continue a conversation.  It's almost the same as
   in 2) but including all the previous exchanges of the current
   request in history.  To do this, call ~eden~ command, press ~c~ and
   enter its title.

You can pause the current conversation in the prompt buffer by calling
~eden~ command and pressing ~SPC~.  Now, request that will be sent to
~eden-api~ will be independant again.

Note that conversation titles and IDs are not stored.  They only
serves during your Emacs session.  Don't worry, your conversations are
not lost forever when you stop your session, you can get it back with
the request ID of the last request in that conversation.  You either
saved the conversation somewhere in your note with its ID or you can
navigate the prompt history with M-p and M-n in the prompt buffer.

* What are requests at point?

When we call ~eden~ preceded by ~C-u~ prefix argument anywhere we get a
menu with accepted actions on the request at point.

Now, if the point is on an ~org-mode~ heading which includes the
property ~eden-org-property-req~ (~EDEN_REQ~ by default), meaning there is
a request at point, we can apply one of the offered actions.

For instance pressing ~c~ will continue a conversation whose last
request is the request at point.

* Managing settings with eden command

In the prompt buffer you can call ~eden~ and press ~S~ to show the current
settings.

In the menu offered by ~eden~, here are the following action that lets
you modify the current settings:

- Press ~a~ to set the current API (~eden-api-set~),
- Press ~m~ to set the model for the current API (~eden-model-set~),
- Press ~T~ to set the temperature (~eden-temperature-set~),
- Press ~'~ to set the system message (~eden-system-message-set~),
- Press ~t~ to toggle the pop-up response (~eden-pops-up-upon-receipt-toggle~).

Here is the complete list of user variables you may want to modify:

- ~eden-api~
- ~eden-apis~
- ~eden-model~
- ~eden-temperature~
- ~eden-system-message~
- ~eden-system-messages~
- ~eden-system-message->developer-for-models~
- ~eden-dir~
- ~eden-org-property-date~
- ~eden-org-property-req~
- ~eden-pops-up-upon-receipt~
- ~eden-prompt-buffer-name~

You can lookup their documentation in the ~*Help*~ buffer using
~describe-variable~ command bound by default to ~C-h v~.

* Adding Perplexity API key

By default, ~eden-api~ variable is set to

#+BEGIN_SRC emacs-lisp
(:service "openai"
 :endpoint "https://api.openai.com/v1/chat/completions"
 :default-model "gpt-4o-mini"
 :models ("gpt-4o-mini" "gpt-4o" "o1-mini" "o1"))
#+END_SRC

such that the requests are sent to OpenAI API.

We've seen in the "Get Started" section that for this to work we need
to add the following line

#+BEGIN_SRC authinfo
machine openai password <openai-api-key>
#+END_SRC

with ~<openai-api-key>~ being OpenAI API key to ~~/.authinfo.gpg~ or
~~/.authinfo~ files.

To use Perplexity API, we can either set ~eden-api~ to

#+BEGIN_SRC emacs-lisp
(:service "perplexity"
 :endpoint "https://api.perplexity.ai/chat/completions")
#+END_SRC

and ~eden-model~ to a model supported by Perplexity API like this

#+BEGIN_SRC emacs-lisp
"llama-3.1-sonar-small-128k-online"
#+END_SRC

or we can select it by calling ~eden~ in the prompt buffer, pressing the
key ~a~ and selecting ~perplexity~.

In both cases we need to add Perplexity API key to one of the two
files mentioned above.

This can be done the same way as for OpenAI API key.  First we provide
our [[https://www.perplexity.ai][Perplexity account]] with some credits ($5.00 is enough to get
started) then we create a Perplexity API key visiting
https://www.perplexity.ai/settings/api and finally we add it to the
correponding file like this

#+BEGIN_SRC authinfo
machine perplexity password <perplexity-api-key>
#+END_SRC

with ~<perplexity-api-key>~ being Perplexity API key.

* Adding an OpenAI-compatible API to eden-apis

Let's say that we want to use X.ai API along with the other
OpenAI-compatible APIs.

To do that, first we add its description to ~eden-apis~ variable like
this:

#+BEGIN_SRC emacs-lisp
(add-to-list 'eden-apis
             '(:service "x.ai"
               :endpoint "https://api.x.ai/v1/chat/completions"
               :default-model "grok-2"
               :models ("grok-beta" "grok-2-latest" "grok-2" "grok-2-12-12")))
#+END_SRC

Then, we provide our [[https://console.x.ai][X.ai ]] with some credits
($5.00 is enough to get started) then we create a X.ai API key in that
same console and finally we add the following line

#+BEGIN_SRC authinfo
machine x.ai password <x.ai-api-key>
#+END_SRC

with ~<x.ai-api-key>~ being X.ai API key to ~~/.authinfo.gpg~ or
~~/.authinfo~ files.

Finally, we can se

we can select X.ai API with ~grok-2~ default model by calling ~eden~ in
the prompt buffer, pressing the key ~a~ and selecting ~x.ai~.
