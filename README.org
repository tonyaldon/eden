Eden is an AI assistant package for Emacs.

It offers a simple interface for:

1) OpenAI LLM models such as ~gpt-4o~ and ~o1~ as well as
2) Perplexity AI powered answer engine.

It also supports any OpenAI-compatible API.

* Get started in minutes

1) Ensure the following utilities are installed and present in one
   of your ~exec-path~ directories:

   - ~curl~
   - ~uuidgen~
   - ~pandoc~

2) Add the directory containing ~eden.el~ to your ~load-path~ and
   require the Eden package by adding the following lines to your init
   file, ensuring to replace ~/path/to/eden/~ with the appropriate
   directory:

   #+BEGIN_SRC emacs-lisp
   (add-to-list 'load-path "/path/to/eden/")
   (require 'eden)
   #+END_SRC

3) Store your OpenAI API key in either the ~~/.authinfo.gpg~ file
   (encrypted with ~gpg~) or the ~~/.authinfo~ file (plaintext):

   - After funding your [[https://platform.openai.com][OpenAI account]] ($5.00 is enough to get
     started), create an OpenAI API key visiting
     https://platform.openai.com/api-keys.
   - Add the API key in the selected file as follows:

     #+BEGIN_SRC authinfo
     machine openai password <openai-api-key>
     #+END_SRC

     where ~<openai-api-key>~ is your API key.

4) Call the command ~eden~ to switch to ~*eden*~ prompt buffer,
5) Enter your prompt,
6) Press ~C-c C-c~ to send your prompt to OpenAI API,
7) Finally, the response will asynchronously show up in a dedicated
   buffer upon receipt.

* Utility requirements

Ensure the following utilities are installed and present in one
of your ~exec-path~ directories:

- ~curl~
- ~uuidgen~
- ~pandoc~

* Eden is simple

Eden is simple and rely exclusively on the ~eden~ command:

1) Use the ~eden~ command to access the prompt buffer at the bottom of
   the frame.  This buffer, in ~eden-mode~, allows you to input prompts
   using ~org-mode~ syntax and send them to ~eden-api~ with the ~eden-send~
   command, bound by default to ~C-c C-c~.

2) When called from the prompt buffer, the ~eden~ command provides a
   transient menu (~eden-menu~) for managing conversations and settings.
   Within this menu, you can:

   - Start a new conversation (hit ~n~),
   - Switch to an existing conversation (hit ~TAB~),
   - Paused a conversation (hit ~SPC~),
   - Show the current settings (hit ~S~),
   - Set the current API (hit ~a~),
   - Set the system message (hit ~'~).

3) Finally, you can also continue or inspect a conversation from a
   request at point by calling ~eden~ with the prefix argument ~C-u~.
   This will bring up ~eden-req-at-point-menu~, offering various actions
   related to the request at point.

* Eden keeps all your requests in eden-dir

A key feature of Eden is its ability to retain all questions asked to
the underlying LLM.

Eden stores each request sent to the OpenAI-compatible API in the
~eden-dir~ directory, which defaults to the ~eden~ subdirectory within
your ~user-emacs-directory~.

Each request is uniquely identified by a UUID, used as a subdirectory
in ~eden-dir~, where relevant information about the request is recorded.

The benefits of this design include:

1) Requests are never lost; you can always retrieve them.
2) If you copy an org heading containing the request's UUID elsewhere,
   you can look up the associated request, access the directory, and
   access details like the request, API, model, system prompt, and
   timestamp.
3) Should an error occur during processing, you can consult the
   ~error.json~ file associated with that request for troubleshooting.
4) You can start or continue a conversation from any existing request
   (a feature known as "branching"):
   - Either from the request at point in your notes,
   - Or navigate through history in the prompt buffer using ~M-p~ and
     ~M-n~ to find the desired request, open the menu with ~eden~, and
     press ~c~ to continue the conversation or press ~s~ to start a new
     conversation from the request.
5) All data is stored in JSON (or text format), facilitating
   integration with other software for further analysis.

* Eden focuses on conversations but doesn't impose it

By default every requests sent are independant.

If you want to have a conversation where previous exchanges are
including belonging to that conversation are sent with newer request,
you have to start or continue a conversation.

There several way to do that while you are in the prompt buffer:

1) You can start a conversation by calling ~eden~ command, pressing ~n~
   and entering its title.  This made that new empty conversation the
   current one, and each new request will be part of it.
2) You can start a conversation from the current request in history
   excluding previous exchanges.  First, use M-p and M-n to navigate
   the prompt history to find the request from which the conversation
   will start.  Then, call ~eden~ command, press ~s~ and enter its title.
   This made that new conversation, with already one exchange, the
   current one, and each new request will be part of it.
3) You can also continue a conversation.  It's almost the same as
   in 2) but including all the previous exchanges of the current
   request in history.  To do this, call ~eden~ command, press ~c~ and
   enter its title.

You can pause the current conversation in the prompt buffer by calling
~eden~ command and pressing ~SPC~.  Now, request that will be sent to
~eden-api~ will be independant again.

Note that conversation titles and IDs are not stored.  They only
serves during your Emacs session.  Don't worry, your conversations are
not lost forever when you stop your session, you can get it back with
the request ID of the last request in that conversation.  You either
saved the conversation somewhere in your note with its ID or you can
navigate the prompt history with M-p and M-n in the prompt buffer.

* What are requests at point?

When we call ~eden~ preceded by ~C-u~ prefix argument anywhere we get a
menu with accepted actions on the request at point.

Now, if the point is on an ~org-mode~ heading which includes the
property ~eden-org-property-req~ (~EDEN_REQ~ by default), meaning there is
a request at point, we can apply one of the offered actions.

For instance pressing ~c~ will continue a conversation whose last
request is the request at point.

* Managing settings with eden command

In the prompt buffer you can call ~eden~ and press ~S~ to show the current
settings.

In the menu offered by ~eden~, here are the following action that lets
you modify the current settings:

- Press ~a~ to set the current API (~eden-api-set~),
- Press ~m~ to set the model for the current API (~eden-model-set~),
- Press ~T~ to set the temperature (~eden-temperature-set~),
- Press ~'~ to set the system message (~eden-system-message-set~),
- Press ~t~ to toggle the pop-up response (~eden-pops-up-upon-receipt-toggle~).

Here is the complete list of user variables you may want to modify:

- ~eden-api~
- ~eden-apis~
- ~eden-model~
- ~eden-temperature~
- ~eden-system-message~
- ~eden-system-messages~
- ~eden-system-message->developer-for-models~
- ~eden-dir~
- ~eden-org-property-date~
- ~eden-org-property-req~
- ~eden-pops-up-upon-receipt~
- ~eden-prompt-buffer-name~

You can lookup their documentation in the ~*Help*~ buffer using
~describe-variable~ command bound by default to ~C-h v~.

* Adding Perplexity API key

By default, ~eden-api~ variable is set to

#+BEGIN_SRC emacs-lisp
(:service "openai"
 :endpoint "https://api.openai.com/v1/chat/completions"
 :default-model "gpt-4o-mini"
 :models ("gpt-4o-mini" "gpt-4o" "o1-mini" "o1"))
#+END_SRC

such that the requests are sent to OpenAI API.

We've seen in the "Get Started" section that for this to work we need
to add the following line

#+BEGIN_SRC authinfo
machine openai password <openai-api-key>
#+END_SRC

with ~<openai-api-key>~ being OpenAI API key to ~~/.authinfo.gpg~ or
~~/.authinfo~ files.

To use Perplexity API, we can either set ~eden-api~ to

#+BEGIN_SRC emacs-lisp
(:service "perplexity"
 :endpoint "https://api.perplexity.ai/chat/completions")
#+END_SRC

and ~eden-model~ to a model supported by Perplexity API like this

#+BEGIN_SRC emacs-lisp
"llama-3.1-sonar-small-128k-online"
#+END_SRC

or we can select it by calling ~eden~ in the prompt buffer, pressing the
key ~a~ and selecting ~perplexity~.

In both cases we need to add Perplexity API key to one of the two
files mentioned above.

This can be done the same way as for OpenAI API key.  First we provide
our [[https://www.perplexity.ai][Perplexity account]] with some credits ($5.00 is enough to get
started) then we create a Perplexity API key visiting
https://www.perplexity.ai/settings/api and finally we add it to the
correponding file like this

#+BEGIN_SRC authinfo
machine perplexity password <perplexity-api-key>
#+END_SRC

with ~<perplexity-api-key>~ being Perplexity API key.

* Adding an OpenAI-compatible API to eden-apis

Let's say that we want to use X.ai API along with the other
OpenAI-compatible APIs.

To do that, first we add its description to ~eden-apis~ variable like
this:

#+BEGIN_SRC emacs-lisp
(add-to-list 'eden-apis
             '(:service "x.ai"
               :endpoint "https://api.x.ai/v1/chat/completions"
               :default-model "grok-2"
               :models ("grok-beta" "grok-2-latest" "grok-2" "grok-2-12-12")))
#+END_SRC

Then, we provide our [[https://console.x.ai][X.ai ]] with some credits
($5.00 is enough to get started) then we create a X.ai API key in that
same console and finally we add the following line

#+BEGIN_SRC authinfo
machine x.ai password <x.ai-api-key>
#+END_SRC

with ~<x.ai-api-key>~ being X.ai API key to ~~/.authinfo.gpg~ or
~~/.authinfo~ files.

Finally, we can se

we can select X.ai API with ~grok-2~ default model by calling ~eden~ in
the prompt buffer, pressing the key ~a~ and selecting ~x.ai~.
